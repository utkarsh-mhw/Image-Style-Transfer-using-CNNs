{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wseA9e7Pz76o"
      },
      "source": [
        "### **Import VGG19 model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "nfI_nuVuSqsQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_model = None\n",
        "content_model = None\n",
        "style_models = None\n",
        "style_cache = {}\n",
        "\n",
        "\n",
        "def initialize_models(content_layer='block5_conv2',\n",
        "                      style_layers=None):\n",
        "    global base_model, content_model, style_models\n",
        "\n",
        "    if style_layers is None:\n",
        "        style_layers = ['block1_conv1', 'block3_conv1', 'block5_conv1']\n",
        "\n",
        "    print(\"Loading VGG19 model...\")\n",
        "    base_model = VGG19(include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "\n",
        "    content_model = Model(\n",
        "        inputs=base_model.input,\n",
        "        outputs=base_model.get_layer(content_layer).output\n",
        "    )\n",
        "\n",
        "\n",
        "    style_models = [\n",
        "        Model(\n",
        "            inputs=base_model.input,\n",
        "            outputs=base_model.get_layer(layer).output\n",
        "        )\n",
        "        for layer in style_layers\n",
        "    ]\n",
        "\n",
        "    print(\"Models loaded successfully\")\n",
        "\n",
        "\n",
        "def load_and_process_image(image_path_or_array, max_dim=512):\n",
        "\n",
        "\n",
        "    if isinstance(image_path_or_array, str):\n",
        "        img = Image.open(image_path_or_array)\n",
        "    elif isinstance(image_path_or_array, Image.Image):\n",
        "        img = image_path_or_array\n",
        "    elif isinstance(image_path_or_array, np.ndarray):\n",
        "        img = Image.fromarray(image_path_or_array.astype('uint8'))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image input type\")\n",
        "\n",
        "\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "\n",
        "    width, height = img.size\n",
        "    scale = max_dim / max(width, height)\n",
        "    if scale < 1:\n",
        "        new_width = int(width * scale)\n",
        "        new_height = int(height * scale)\n",
        "        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "\n",
        "def deprocess_image(processed_img):\n",
        "\n",
        "    if len(processed_img.shape) == 4:\n",
        "        processed_img = np.squeeze(processed_img, axis=0)\n",
        "\n",
        "\n",
        "    x = processed_img.copy()\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "    return Image.fromarray(x)\n",
        "\n",
        "\n",
        "def compute_content_cost(content_features, generated_features):\n",
        "\n",
        "    return tf.reduce_mean(tf.square(content_features - generated_features))\n",
        "\n",
        "\n",
        "def compute_gram_matrix(features):\n",
        "\n",
        "    channels = int(features.shape[-1])\n",
        "    a = tf.reshape(features, [-1, channels])\n",
        "    n = tf.shape(a)[0]\n",
        "    gram = tf.matmul(a, a, transpose_a=True)\n",
        "    return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "\n",
        "def compute_style_cost(style_features_list, generated_features_list):\n",
        "\n",
        "    style_weight = 1.0 / len(style_models)\n",
        "    total_style_cost = 0.0\n",
        "\n",
        "    for style_features, generated_features in zip(\n",
        "        style_features_list, generated_features_list\n",
        "    ):\n",
        "        gram_style = compute_gram_matrix(style_features)\n",
        "        gram_generated = compute_gram_matrix(generated_features)\n",
        "        layer_cost = tf.reduce_mean(tf.square(gram_style - gram_generated))\n",
        "        total_style_cost += style_weight * layer_cost\n",
        "\n",
        "    return total_style_cost\n",
        "\n",
        "\n",
        "def get_style_features(style_image, cache_key=None):\n",
        "\n",
        "    global style_cache\n",
        "\n",
        "    if cache_key and cache_key in style_cache:\n",
        "        print(f\"Using cached style features for '{cache_key}'\")\n",
        "        return style_cache[cache_key]\n",
        "\n",
        "    features = [model(style_image) for model in style_models]\n",
        "\n",
        "    if cache_key:\n",
        "        style_cache[cache_key] = features\n",
        "        print(f\"Cached style features as '{cache_key}'\")\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def transfer_style(content_image, style_image,\n",
        "                   iterations=300, alpha=1.0, beta=1e4,\n",
        "                   learning_rate=5.0, style_cache_key=None,\n",
        "                   progress_callback=None):\n",
        "\n",
        "    print(f\"Starting style transfer ({iterations} iterations)...\")\n",
        "    print(f\"Alpha (content weight): {alpha}, Beta (style weight): {beta}\")\n",
        "\n",
        "\n",
        "    content_features = content_model(content_image)\n",
        "    style_features = get_style_features(style_image, style_cache_key)\n",
        "\n",
        "\n",
        "    generated = tf.Variable(content_image, dtype=tf.float32)\n",
        "\n",
        "\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\n",
        "    best_cost = float('inf')\n",
        "    best_image = None\n",
        "\n",
        "\n",
        "    for i in range(iterations):\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            gen_content_features = content_model(generated)\n",
        "            gen_style_features = [model(generated) for model in style_models]\n",
        "\n",
        "\n",
        "            content_cost = compute_content_cost(\n",
        "                content_features, gen_content_features\n",
        "            )\n",
        "            style_cost = compute_style_cost(\n",
        "                style_features, gen_style_features\n",
        "            )\n",
        "\n",
        "            total_cost = alpha * content_cost + beta * style_cost\n",
        "\n",
        "\n",
        "        gradients = tape.gradient(total_cost, generated)\n",
        "        optimizer.apply_gradients([(gradients, generated)])\n",
        "\n",
        "        if total_cost < best_cost:\n",
        "            best_cost = total_cost\n",
        "            best_image = generated.numpy()\n",
        "\n",
        "\n",
        "        if progress_callback and (i % 10 == 0 or i == iterations - 1):\n",
        "            progress_callback(i + 1, float(total_cost), generated.numpy())\n",
        "\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"  Iteration {i}/{iterations} - Total: {total_cost:.2f}, Content: {content_cost:.2f}, Style: {style_cost:.2f}\")\n",
        "\n",
        "    print(f\"Style transfer complete! Final cost: {best_cost:.2f}\")\n",
        "\n",
        "    return best_image, float(best_cost)\n",
        "\n",
        "\n",
        "def apply_style(content_input, style_input,\n",
        "                style_weight=0.5, iterations=300,\n",
        "                max_dim=512, alpha=1.0, beta=None,\n",
        "                learning_rate=5.0, style_cache_key=None,\n",
        "                progress_callback=None):\n",
        "\n",
        "\n",
        "    if base_model is None:\n",
        "        initialize_models()\n",
        "\n",
        "\n",
        "    content_image = load_and_process_image(content_input, max_dim)\n",
        "    style_image = load_and_process_image(style_input, max_dim)\n",
        "\n",
        "\n",
        "    if beta is None:\n",
        "        beta = style_weight * 1e4\n",
        "\n",
        "\n",
        "    result_array, final_cost = transfer_style(\n",
        "        content_image=content_image,\n",
        "        style_image=style_image,\n",
        "        iterations=iterations,\n",
        "        alpha=alpha,\n",
        "        beta=beta,\n",
        "        learning_rate=learning_rate,\n",
        "        style_cache_key=style_cache_key,\n",
        "        progress_callback=progress_callback\n",
        "    )\n",
        "\n",
        "\n",
        "    result_image = deprocess_image(result_array)\n",
        "\n",
        "    return result_image\n",
        "\n",
        "\n",
        "\n",
        "def quick_style_transfer(content_path, style_path, style_weight=0.5, iterations=300):\n",
        "\n",
        "    result = apply_style(\n",
        "        content_input=content_path,\n",
        "        style_input=style_path,\n",
        "        style_weight=style_weight,\n",
        "        iterations=iterations\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def compare_style_weights(content_path, style_path, weights=[0.3, 0.5, 0.7], iterations=200):\n",
        "\n",
        "    results = []\n",
        "    for weight in weights:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Testing style_weight = {weight}\")\n",
        "        print('='*50)\n",
        "        result = apply_style(\n",
        "            content_input=content_path,\n",
        "            style_input=style_path,\n",
        "            style_weight=weight,\n",
        "            iterations=iterations\n",
        "        )\n",
        "        results.append((weight, result))\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    initialize_models()\n",
        "\n",
        "\n",
        "    result = apply_style(\n",
        "        content_input='japanese_garden.jpg',\n",
        "        style_input='picasso_selfportrait.jpg',\n",
        "        style_weight=0.5,\n",
        "        iterations=300\n",
        "    )\n",
        "\n",
        "    result.save('result.jpg')\n",
        "    print(\"Saved result to result.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsbWgfla0zS5",
        "outputId": "b28e4e58-1544-430d-d5d5-45e2108be439"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading VGG19 model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "✓ Models loaded successfully!\n",
            "Starting style transfer (300 iterations)...\n",
            "Alpha (content weight): 1.0, Beta (style weight): 5000.0\n",
            "  Iteration 0/300 - Total: 798199119872.00, Content: 0.00, Style: 159639824.00\n",
            "  Iteration 50/300 - Total: 10835549184.00, Content: 3863.83, Style: 2167109.00\n",
            "  Iteration 100/300 - Total: 5340538880.00, Content: 4019.80, Style: 1068107.00\n",
            "  Iteration 150/300 - Total: 3937910784.00, Content: 4088.83, Style: 787581.31\n",
            "  Iteration 200/300 - Total: 3194964480.00, Content: 4138.82, Style: 638992.06\n",
            "  Iteration 250/300 - Total: 2712075008.00, Content: 4171.62, Style: 542414.19\n",
            "✓ Style transfer complete! Final cost: 2371082240.00\n",
            "Saved result to result.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mO4Tlgx0zIe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}